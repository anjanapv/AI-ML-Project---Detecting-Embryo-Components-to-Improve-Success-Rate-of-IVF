{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "105e66f2",
   "metadata": {},
   "source": [
    "**Data Description**\n",
    "\n",
    "\n",
    "In the process of In Vitro Fertilisation embryos are cultivated in an incubator for 3â€“5 days until they reach the blastocyst stage in IVF, which is a manual fertilisation method. The best embryos (blastocysts) are chosen based on important morphological characteristics and returned to the uterus of the patient.\n",
    "\n",
    "The dataset included Hoffman Modulation Contrast (HMC) microscopic blastocyst images captured by an Olympus IX71 inverted microscope using the Research Instrument Cronus 4 software (Falmouth, England). All images were captured at magnifications of 1.6 and 20 and objective lens. These images are from the different patients who were treated at Pacific Center for Reproduction Canada between 2012 to 2016, images are randomly chosen with a good focus on both TE and ICM. These blastocyst images were manually labeled by expert embryologists for blastocyst components. The labeled images, called ground truth (GT), were collectively made available for research purposes with the approval of the Canadian Research Ethics Board on 24 May 2017.\n",
    "\n",
    "The dataset consists of 592 unique blastocyst RGB images. These images can be used to train the model to segment each image into its components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3afdb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install segmentation_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9821b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bd1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226b5349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'None/Data'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='D:\\College\\Sem 4\\Capstone\\Capstone Project\\AI-ML-Project---Detecting-Embryo-Components-to-Improve-Success-Rate-of-IVF\\EDA'\n",
    "data_path='D:\\College\\Sem 4\\Capstone\\Capstone Project\\AI-ML-Project---Detecting-Embryo-Components-to-Improve-Success-Rate-of-IVF\\Data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45ba2c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None/Data\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'None/Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_52656/1186583837.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{train_dir}'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'None/Data'"
     ]
    }
   ],
   "source": [
    "#provide the dataset path below\n",
    "\n",
    "train_dir = get_data_path(path)\n",
    "print(train_dir)\n",
    "imgs = [fn for fn in os.listdir(f'{train_dir}') if fn.endswith('.jpg')]\n",
    "def get_data(path,imgs):\n",
    "    \n",
    "    data=[]\n",
    "    for img in imgs:\n",
    "        file = f'{train_dir}{img}'\n",
    "        file_image = image.load_img(file)\n",
    "        img_read = cv2.imread(f'{train_dir}{img}')\n",
    "        height, width, channel = img_read.shape\n",
    "        data.append(list([img,file_image,height,width,channel]))\n",
    "    df = pd.DataFrame(data, columns=['Label','Image','Height','Width','Channel'])\n",
    "    return df\n",
    "df=get_data(train_dir,imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5fefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting random images\n",
    "def plot_img():\n",
    "    for i in range(6):\n",
    "        select_img = np.random.choice(imgs, 6, replace = False)\n",
    "        file = f'{train_dir}{select_img[i]}'\n",
    "        file_load=image.load_img(file)\n",
    "        plt.imshow(file_load)\n",
    "        plt.title(select_img[i])\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "plot_img()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04944c",
   "metadata": {},
   "source": [
    "There are five components in each blastocyst that needs to segmented which are trophoblast, blastocoel, Zona pellucida, inner cell mass and the cell background.\n",
    "\n",
    "Inner cell mass: The blastocyst is a structure formed in the early development of mammals. It possesses an inner cell mass (ICM) which subsequently forms the embryo. This layer surrounds the inner cell mass and a fluid-filled cavity known as the blastocoel. Trophectoderm: The outer layer of the blastocyst consists of cells collectively called the trophoblast. The trophoblast gives rise to the chorion and amnion that surround the embryo. The trophectoderm which is a part of trophoblast does not become part of the fetus but does become some of the supporting structures, such as the placenta. Zona Pellucida: The zona pellucida is essential for oocyte growth and fertilization. Blastocoel: The blastocoel provides support for structural movement and becomes a fluid layer as part of the developing digestive tract. Cell Background: Background of the cell\n",
    "\n",
    "**Semantic Segmentation** is the process of assigning a label to every pixel in the image. The componenets of Blastocyst images can be seperated by using semantic segmentation.\n",
    "\n",
    "![blastocyst](R12-0090A.jpg)\n",
    "Blastocyst\n",
    "![Blastocoel](R12-0090A-Blastocoel.jpg)\n",
    "blastocoel\n",
    "![ICM](R12-0090A-ICM.jpg)\n",
    "Inner Cell Mass\n",
    "![TE](R12-0090A-TE.jpg)\n",
    "Trophoblast\n",
    "![ZP](R12-0090A-ZP.jpg)\n",
    "Zona pellucida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to look into this code to understand image matrix\n",
    "\n",
    "def img2np(path, list_of_filename, size = (64, 64)):\n",
    "    # iterating through each file\n",
    "    for fn in list_of_filename:\n",
    "        fp = path + fn\n",
    "        current_image = image.load_img(fp, target_size = size, \n",
    "                                       color_mode = 'grayscale')\n",
    "        # convert image to a matrix\n",
    "        img_ts = image.img_to_array(current_image)\n",
    "        # turn that into a vector / 1D array\n",
    "        img_ts = [img_ts.ravel()]\n",
    "        try:\n",
    "            # concatenate different images\n",
    "            full_mat = np.concatenate((full_mat, img_ts))\n",
    "        except UnboundLocalError: \n",
    "            # if not assigned yet, assign one\n",
    "            full_mat = img_ts\n",
    "    return full_mat\n",
    "\n",
    "# run it on our folders\n",
    "np_images = img2np(f'{train_dir}', imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210071c9",
   "metadata": {},
   "source": [
    "**Data Quality**\n",
    "\n",
    "The dataset consists of 592 RGB images with average height of 398.28 pixel and Width of 435.48 pixel.\n",
    "The total images has 156 unique height and 196 unique width.\n",
    "There are 3 channels in each image. The quality of image is good to train the model on sprint semantic segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336109d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[[\"Height\", \"Width\", \"Channel\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Height'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Width'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4161be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Height'])\n",
    "plt.title(\"Histogram on image Height\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf2237",
   "metadata": {},
   "source": [
    "**The height of images in the dataset is normally distributed and does not have any skewness.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1928fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['Width'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1d4bd",
   "metadata": {},
   "source": [
    "**The width of the image is normally distributed and we can observe an outlier which can be considered as an exception.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6ab733",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=df['Height'],y=df['Width'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf1462",
   "metadata": {},
   "source": [
    "**The above scatter plot demonstrates the distribution of height and width of the images in the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60fedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install deon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d59803",
   "metadata": {},
   "source": [
    "**Data Fitness**\n",
    "\n",
    "The dataset consists of 592 unique images which wouldn't be sufficient for training the model. Therefore we would use Data augmentation to add more training data. Data Augmentation would be used to increase the amount of data by adding slightly modified copies of already existing data.\n",
    "\n",
    "Yes, we would employ this dataset to answer the research question.\n",
    "\n",
    "This dataset was approved by the **Canadian Research Ethics Board** on 24 May 2017.\n",
    "\n",
    "**Consent**\n",
    "\n",
    "The data is publicly available to everyone in the form of an image dataset, and it is used only for experimental purposes. It contains the images of an embryo(blastocyst) and the components, for which we need to find the confidence percentage, area, radius, and thickness to identify whether it is the right embryo to transfer or not. There is no information provided about the details of patients, whose embryo images are taken at PCRM by using an Olympus IX71 inverted microscope during the years between 2012 and 2016.\n",
    "\n",
    "**Clarity**\n",
    "\n",
    "Clarity is closely related to consent because its unethical to do anything without the proper consent and it should be clearly mentioned about how the data is going to be used. We are using this data to accurately identify the embryo to improve the success rate of in-vitro fertilization. In this analysis, we will use sprint semantic segmentation network (SSS-Net) to automatically detect the components of blastocysts, whose specific morphologies are considered to determine the viability of an embryo for in-vitro fertilization.\n",
    "\n",
    "**Consistency**\n",
    "\n",
    "The data is safeguarded in a vault at Simon Fraser University, but it is publicly available to everyone for experimental purposes. There is no personal information about the details of patients available for this dataset. This image dataset is using only to detect the embryos for improving the in-vitro fertilization success rate.\n",
    "\n",
    "**Control**\n",
    "\n",
    "We should have the control on the data, on how its going to be used. The data can be accessed by everyone because it is publicly available, and it is using only for research purposes in various health sectors.\n",
    "\n",
    "**Consequences**\n",
    "\n",
    "The finding from the analysis of the dataset is using only to improve the success rate of in-vitro fertilization. There would not be any consequences due to the use of the dataset unless the personal information is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ca648",
   "metadata": {},
   "source": [
    "**Github repository links**\n",
    "\n",
    "Collaborate Link : https://github.com/anjanapv/AI-ML-Project---Detecting-Embryo-Components-to-Improve-Success-Rate-of-IVF\n",
    "\n",
    "Nobin Ann Mathew: https://github.com/NobinMath\n",
    "\n",
    "Anjana Padikkal Veetil: https://github.com/anjanapv\n",
    "\n",
    "Amal Mathew: https://github.com/Amalmathew5\n",
    "\n",
    "Venkata Bhagya Teja Maridu :https://github.com/tejamaridu\n",
    "\n",
    "Santosh Kumar Kantimahanti Lakshmi Venkata :https://github.com/santoshkumarklv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e96e759a2ee65bed98a5fd80cb45ec0c9b979a2ece1d06bcb51d95bed62a4083"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('DAB300')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
